env:
  name: "GridLife-v0"
  horizon: 512
  partial_observability: true
internal_state:
  dims: ["energy","temp","integrity"]
  mu: [0.7, 0.5, 0.9]
  w:  [1.0, 0.5, 1.5]
viability:
  constraints:
    - "energy >= 0.2"
    - "temp in [0.3, 0.7]"
    - "integrity >= 0.6"
  shield:
    conf: 0.97
    horizon: 8
rewards:
  lambda_homeo: 0.7
  lambda_intr:  0.3
  intrinsic: "empowerment"  # or "surprise" or "rnd"
train:
  algo: "SAC"        # or PPO/TD3
  batch_size: 1024
  gamma: 0.995
  update_every: 64
  model_rollouts: 5
  amortize_after_steps: 20000 # Steps before switching to amortized shield

curriculum:
  enabled: true
  steps: 50000
  lambda_homeo:
    start: 0.1
    end: 0.7
  lambda_intr:
    start: 0.05
    end: 0.3
  viability_constraints:
    - dim_name: "energy"
      comparison: ">="
      start: 0.05
      end: 0.2
    - dim_name: "temp_min"
      comparison: ">="
      start: 0.1
      end: 0.3
    - dim_name: "temp_max"
      comparison: "<="
      start: 0.9
      end: 0.7
    - dim_name: "integrity"
      comparison: ">="
      start: 0.3
      end: 0.6

safety_network:
  hidden_dim: 128
  lr: 0.0001

demonstrations:
  filepath: "demonstrations/expert_demonstrations.npz"

state_estimator:
  hidden_dim: 128
  n_layers: 2
  lr: 0.001
  sequence_length: 16

empowerment:
  k: 4
  hidden_dim: 256
  lr: 0.0001

meta_learning:
  enabled: true
  learning_rate: 0.01
  update_frequency: 50 # Update mu every 50 episodes